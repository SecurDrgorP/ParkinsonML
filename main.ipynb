{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"pd_speech_features.csv\", header=1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns[1:-1]\n",
    "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "\n",
    "\n",
    "# Identify binary/categorical columns and other features\n",
    "binary_features = ['gender']  # Adjust if needed\n",
    "other_features = [col for col in data.columns if col not in binary_features + ['id', 'class']]\n",
    "\n",
    "# Apply PCA to non-binary features\n",
    "pca = PCA(n_components=20)  # Retain 95% of the explained variance\n",
    "pca_features = pca.fit_transform(data[other_features])\n",
    "pca_feature_names = [f'PC{i+1}' for i in range(pca_features.shape[1])]\n",
    "\n",
    "# Create a PCA DataFrame and add the ID column for grouping\n",
    "pca_df = pd.DataFrame(pca_features, columns=pca_feature_names)\n",
    "pca_df['id'] = data['id']\n",
    "\n",
    "# Aggregate PCA-transformed features with mean and std\n",
    "aggregated_pca_data = pca_df.groupby('id').agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Flatten multi-level column names\n",
    "aggregated_pca_data.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in aggregated_pca_data.columns]\n",
    "\n",
    "# Add binary features back as-is\n",
    "for feature in binary_features:\n",
    "    aggregated_pca_data[feature] = data.groupby('id')[feature].first().values.astype(data[feature].dtype)\n",
    "\n",
    "\n",
    "# Add the target variable\n",
    "aggregated_pca_data['class'] = data.groupby('id')['class'].first().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PC6_std', 'gender', 'PC18_std', 'PC1_mean', 'PC5_mean', 'PC19_std', 'PC19_mean', 'PC20_mean', 'PC20_std', 'PC6_mean', 'PC4_std', 'PC7_mean']\n"
     ]
    }
   ],
   "source": [
    "from EFSA.main import FeatureSelector\n",
    "\n",
    "# Feature matrix (X) and target vector (y)\n",
    "X = aggregated_pca_data.drop('class', axis=1)\n",
    "y = aggregated_pca_data['class']\n",
    "\n",
    "\n",
    "selector = FeatureSelector(X=X, y=y)\n",
    "\n",
    "selected_features = selector.comprehensive_feature_selection(k_features=20)\n",
    "\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM on X_reduced - Accuracy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.36      0.45        14\n",
      "           1       0.79      0.92      0.85        37\n",
      "\n",
      "    accuracy                           0.76        51\n",
      "   macro avg       0.71      0.64      0.65        51\n",
      "weighted avg       0.75      0.76      0.74        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM model on X_reduced (which is the PCA-reduced data)\n",
    "model1 = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# For X_reduced\n",
    "model1.fit(X_train, y_train)  # Train on the reduced training data\n",
    "y_pred_reduced = model1.predict(X_test)  # Make predictions on the test data\n",
    "\n",
    "print(f\"SVM on X_reduced - Accuracy:\\n {classification_report(y_test, y_pred_reduced)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
